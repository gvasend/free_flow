{"sk_make_circles": {"arguments": {"zero_based": {"description": "ZERO_BASED"}, "factor": {"description": "FACTOR"}, "multilabel": {"description": "MULTILABEL\""}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "noise": {"description": "NOISE"}, "query_id": {"description": "QUERY_ID"}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}, "help": {"description": "show this help message and exit"}, "type": {"description": "TYPE"}, "comment": {"description": "COMMENT"}, "shuffle": {"description": "SHUFFLE  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "n_samples": {"description": "N_SAMPLES"}}, "path": "./"}, "sk_rf": {"arguments": {"n_estimators": {"description": "N_ESTIMATORS                        The number of trees in the forest."}, "warm_start": {"description": "WARM_START                        When set to True, reuse the solution of the previous                        call to fit and add more estimators to the ensemble,                        otherwise, just fit a whole new forest."}, "class_weight": {"description": "CLASS_WEIGHT                        list of dicts, balanced, balanced_subsample or None,                        optional (default=None) Weights associated with                        classes in the form {class_label: weight}. If not                        given, all classes are supposed to have weight one.                        For multi-output problems, a list of dicts can be                        provided in the same order as the columns of y. The                        balanced mode uses the values of y to automatically                        adjust weights inversely proportional to class                        frequencies in the input data as n_samples /                        (n_classes * np.bincount(y)) The balanced_subsample                        mode is the same as balanced except that weights are                        computed based on the bootstrap sample for every tree                        grown. For multi-output, the weights of each column of                        y will be multiplied. Note that these weights will be                        multiplied with sample_weight (passed through the fit                        method) if sample_weight is specified.\""}, "min_impurity_split": {"description": "MIN_IMPURITY_SPLIT                        Threshold for early stopping in tree growth. A node                        will split if its impurity is above the threshold,                        otherwise it is a leaf. New in version 0.18."}, "min_samples_split": {"description": "MIN_SAMPLES_SPLIT                        The minimum number of samples required to split an                        internal node: If int, then consider min_samples_split                        as the minimum number. If float, then                        min_samples_split is a percentage and                        ceil(min_samples_split * n_samples) are the minimum                        number of samples for each split. Changed in version                        0.18: Added float values for percentages."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "oob_score": {"description": "OOB_SCORE                        Whether to use out-of-bag samples to estimate the                        generalization accuracy."}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "max_features": {"description": "MAX_FEATURES                        The number of features to consider when looking for                        the best split: If int, then consider max_features                        features at each split. If float, then max_features is                        a percentage and int(max_features * n_features)                        features are considered at each split. If auto, then                        max_features=sqrt(n_features). If sqrt, then                        max_features=sqrt(n_features) (same as auto). If log2,                        then max_features=log2(n_features). If None, then                        max_features=n_features. Note: the search for a split                        does not stop until at least one valid partition of                        the node samples is found, even if it requires to                        effectively inspect more than max_features features."}, "min_samples_leaf": {"description": "MIN_SAMPLES_LEAF                        The minimum number of samples required to be at a leaf                        node: If int, then consider min_samples_leaf as the                        minimum number. If float, then min_samples_leaf is a                        percentage and ceil(min_samples_leaf * n_samples) are                        the minimum number of samples for each node. Changed                        in version 0.18: Added float values for percentages."}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "random_state": {"description": "RANDOM_STATE                        A pseudo random number generator used for the                        initialization of the residuals when eigen_solver ==                        arpack."}, "verbose": {"description": "VERBOSE     Enable verbose output. Note that this setting takes                        advantage of a per-process runtime setting in libsvm                        that, if enabled, may not work properly in a                        multithreaded context."}, "min_weight_fraction_leaf": {"description": "MIN_WEIGHT_FRACTION_LEAF                        The minimum weighted fraction of the sum total of                        weights (of all the input samples) required to be at a                        leaf node. Samples have equal weight when                        sample_weight is not provided."}, "bootstrap": {"description": "BOOTSTRAP                        Whether bootstrap samples are used when building                        trees."}, "help": {"description": "show this help message and exit"}, "max_depth": {"description": "MAX_DEPTH                        The maximum depth of the tree. If None, then nodes are                        expanded until all leaves are pure or until all leaves                        contain less than min_samples_split samples."}, "criterion": {"description": "CRITERION                        The function to measure the quality of a split.                        Supported criteria are gini for the Gini impurity and                        entropy for the information gain."}, "max_leaf_nodes": {"description": "MAX_LEAF_NODES                        Grow trees with max_leaf_nodes in best-first fashion.                        Best nodes are defined as relative reduction in                        impurity. If None then unlimited number of leaf nodes."}, "n_jobs": {"description": "N_JOBS       The number of jobs to use for the computation. This                        works by computing each of the n_init runs in                        parallel. If -1 all CPUs are used. If 1 is given, no                        parallel computing code is used at all, which is                        useful for debugging. For n_jobs below -1, (n_cpus + 1                        + n_jobs) are used. Thus for n_jobs = -2, all CPUs but                        one are used."}}, "path": "./"}, "sk_make_s_curve": {"arguments": {"argf": {"description": "ARGF           Read command line arguments from a file."}, "noise": {"description": "NOISE         The standard deviation of the gaussian noise."}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}, "zero_based": {"description": "ZERO_BASED"}, "random_state": {"description": "RANDOM_STATE                        RandomState instance or None, optional (default=None)                        If int, random_state is the seed used by the random                        number generator; If RandomState instance,                        random_state is the random number generator; If None,                        the random number generator is the RandomState                        instance used by np.random.  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "multilabel": {"description": "MULTILABEL\""}, "comment": {"description": "COMMENT"}, "query_id": {"description": "QUERY_ID"}, "help": {"description": "show this help message and exit"}, "n_samples": {"description": "N_SAMPLES"}}, "path": "./"}, "sk_kmeans": {"arguments": {"model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "n_clusters": {"description": "N_CLUSTERS                        The number of clusters to form as well as the number                        of centroids to generate."}, "help": {"description": "show this help message and exit"}, "precompute_distances": {"description": "{auto,True,False}                        Precompute distances (faster but takes more memory).                        \\xe2\\x80\\x98auto\\xe2\\x80\\x99 : do not precompute distances if n_samples *                        n_clusters > 12 million. This corresponds to about                        100MB overhead per job using double precision. True :                        always precompute distances False : never precompute                        distances"}, "max_iter": {"description": "MAX_ITER   Maximum number of iterations of the k-means algorithm                        for a single run."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "tol": {"description": "TOL             Relative tolerance with regards to inertia to declare                        convergence"}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}\""}, "algorithm": {"description": "{auto,full,elkan}                        K-means algorithm to use. The classical EM-style                        algorithm is \\xe2\\x80\\x9cfull\\xe2\\x80\\x9d. The \\xe2\\x80\\x9celkan\\xe2\\x80\\x9d variation is more                        efficient by using the triangle inequality, but                        currently doesn\\xe2\\x80\\x99t support sparse data. \\xe2\\x80\\x9cauto\\xe2\\x80\\x9d chooses                        \\xe2\\x80\\x9celkan\\xe2\\x80\\x9d for dense data and \\xe2\\x80\\x9cfull\\xe2\\x80\\x9d for sparse data."}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "random_state": {"description": "RANDOM_STATE                        The generator used to initialize the centers. If an                        integer is given, it fixes the seed. Defaults to the                        global numpy random number generator."}, "verbose": {"description": "VERBOSE     Verbosity mode."}, "init": {"description": "{k-means++,random,ndarray}                        Method for initialization, defaults to k-means++:                        k-means++ : selects initial cluster centers for k-mean                        clustering in a smart way to speed up convergence. See                        section Notes in k_init for more details. random:                        choose k observations (rows) at random from data for                        the initial centroids. If an ndarray is passed, it                        should be of shape (n_clusters, n_features) and gives                        the initial centers."}, "copy_x": {"description": "COPY_X       When pre-computing distances it is more numerically                        accurate to center the data first. If copy_x is True,                        then the original data is not modified. If False, the                        original data is modified, and put back before the                        function returns, but small numerical differences may                        be introduced by subtracting and then adding the data                        mean.  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "n_init": {"description": "N_INIT       Number of time the k-means algorithm will be run with                        different centroid seeds. The final results will be                        the best output of n_init consecutive runs in terms of                        inertia."}, "n_jobs": {"description": "N_JOBS       The number of jobs to use for the computation. This                        works by computing each of the n_init runs in                        parallel. If -1 all CPUs are used. If 1 is given, no                        parallel computing code is used at all, which is                        useful for debugging. For n_jobs below -1, (n_cpus + 1                        + n_jobs) are used. Thus for n_jobs = -2, all CPUs but                        one are used."}}, "path": "./"}, "sk_kpca": {"arguments": {"kernel": {"description": "{linear,poly,rbf,sigmoid,cosine,precomputed}                        number of components to use in PCA analysis"}, "zero_based": {"description": "ZERO_BASED"}, "help": {"description": "show this help message and exit"}, "degree": {"description": "DEGREE       Degree for poly kernels. Ignored by other kernels."}, "multilabel": {"description": "MULTILABEL\""}, "tol": {"description": "TOL             Convergence tolerance for arpack. If 0, optimal value                        will be chosen by arpack."}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "eigen_solver": {"description": "{auto,dense,arpack}                        Select eigensolver to use. If n_components is much                        less than the number of training samples, arpack may                        be more efficient than the dense eigensolver"}, "gamma": {"description": "GAMMA         Kernel coefficient for rbf and poly kernels. Ignored                        by other kernels."}, "plot": {"description": "{no,save,show}                        plot options: no, save, show"}, "n_components": {"description": "N_COMPONENTS                        number of components to use in PCA analysis"}, "coef0": {"description": "COEF0         Independent term in poly and sigmoid kernels. Ignored                        by other kernels."}, "fit_inverse_transform": {"description": "FIT_INVERSE_TRANSFORM                        Learn the inverse transform for non-precomputed                        kernels. (i.e. learn to find the pre-image of a point)"}, "n_jobs": {"description": "N_JOBS       The number of parallel jobs to run. If -1, then the                        number of jobs is set to the number of CPU cores."}, "copy_X": {"description": "COPY_X       If True, input X is copied and stored by the model in                        the X_fit_ attribute. If no further changes will be                        done to X, setting copy_X=False saves memory by                        storing a reference."}, "max_iter": {"description": "MAX_ITER   Maximum number of iterations for arpack. If None,                        optimal value will be chosen by arpack."}, "kernel_params": {"description": "KERNEL_PARAMS                        Parameters (keyword arguments) and values for kernel                        passed as callable object. Ignored by other kernels."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "random_state": {"description": "RANDOM_STATE                        A pseudo random number generator used for the                        initialization of the residuals when eigen_solver ==                        \\xe2\\x80\\x98arpack\\xe2\\x80\\x99."}, "remove_zero_eig": {"description": "REMOVE_ZERO_EIG                        If True, then all components with zero eigenvalues are                        removed, so that the number of components in the                        output may be < n_components (and sometimes even zero                        due to numerical instability). When n_components is                        None, this parameter is ignored and components with                        zero eigenvalues are removed regardless."}, "alpha": {"description": "ALPHA         Hyperparameter of the ridge regression that learns the                        inverse transform (when fit_inverse_transform=True)."}, "query_id": {"description": "QUERY_ID"}, "comment": {"description": "COMMENT"}, "plot_title": {"description": "PLOT_TITLE                        Title for the plot"}}, "path": "./"}, "sk_mean_shift": {"arguments": {"comment": {"description": "COMMENT"}, "zero_based": {"description": "ZERO_BASED"}, "help": {"description": "show this help message and exit"}, "bandwidth": {"description": "BANDWIDTH                        Bandwidth used in the RBF kernel. If not given, the                        bandwidth is estimated using                        sklearn.cluster.estimate_bandwidth"}, "multilabel": {"description": "MULTILABEL  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "components": {"description": "COMPONENTS                        number of components to use in PCA analysis"}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}"}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "min_bin_freq": {"description": "MIN_BIN_FREQ                        To speed up the algorithm, accept only those bins with                        at least min_bin_freq points as seeds. If not defined,                        set to 1."}, "argf": {"description": "ARGF           Read command line arguments from a file.\""}, "seeds": {"description": "SEEDS         shape=[n_samples, n_features], Seeds used to                        initialize kernels. If not set, the seeds are                        calculated by clustering.get_bin_seeds with bandwidth                        as the grid size and default values for other                        parameters."}, "bin_seeding": {"description": "BIN_SEEDING                        If true, initial kernel locations are not locations of                        all points, but rather the location of the discretized                        version of points, where points are binned onto a grid                        whose coarseness corresponds to the bandwidth. Setting                        this option to True will speed up the algorithm                        because fewer seeds will be initialized. default                        value: False Ignored if seeds argument is not None."}, "query_id": {"description": "QUERY_ID"}, "cluster_all": {"description": "CLUSTER_ALL                        If true, then all points are clustered, even those                        orphans that are not within any kernel. Orphans are                        assigned to the nearest kernel. If false, then orphans                        are given cluster label -1."}, "n_jobs": {"description": "N_JOBS       The number of jobs to use for the computation. This                        works by computing each of the n_init runs in                        parallel. If -1 all CPUs are used. If 1 is given, no                        parallel computing code is used at all, which is                        useful for debugging. For n_jobs below -1, (n_cpus + 1                        + n_jobs) are used. Thus for n_jobs = -2, all CPUs but                        one are used."}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}}, "path": "./"}, "sfabric": {"arguments": {"help": {"description": "show this help message and exit"}, "bridge": {"description": "BRIDGE     which bridge to use'"}}, "path": "./"}, "sk_kernel_pca": {"arguments": {"kernel": {"description": "{linear,poly,rbf,sigmoid,cosine,precomputed}                        number of components to use in PCA analysis"}, "fit_inverse_transform": {"description": "FIT_INVERSE_TRANSFORM                        Learn the inverse transform for non-precomputed                        kernels. (i.e. learn to find the pre-image of a point)"}, "eigen_solver": {"description": "{auto,dense,arpack}                        Select eigensolver to use. If n_components is much                        less than the number of training samples, arpack may                        be more efficient than the dense eigensolver"}, "help": {"description": "show this help message and exit"}, "max_iter": {"description": "MAX_ITER   Maximum number of iterations for arpack. If None,                        optimal value will be chosen by arpack."}, "kernel_params": {"description": "KERNEL_PARAMS                        Parameters (keyword arguments) and values for kernel                        passed as callable object. Ignored by other kernels."}, "degree": {"description": "DEGREE       Degree for poly kernels. Ignored by other kernels."}, "copy_X": {"description": "COPY_X       If True, input X is copied and stored by the model in                        the X_fit_ attribute. If no further changes will be                        done to X, setting copy_X=False saves memory by                        storing a reference."}, "tol": {"description": "TOL             Convergence tolerance for arpack. If 0, optimal value                        will be chosen by arpack."}, "n_components": {"description": "N_COMPONENTS                        number of components to use in PCA analysis"}, "gamma": {"description": "GAMMA         Kernel coefficient for rbf and poly kernels. Ignored                        by other kernels."}, "argf": {"description": "ARGF           Read command line arguments from a file.\""}, "random_state": {"description": "RANDOM_STATE                        A pseudo random number generator used for the                        initialization of the residuals when eigen_solver ==                        \\xe2\\x80\\x98arpack\\xe2\\x80\\x99."}, "remove_zero_eig": {"description": "REMOVE_ZERO_EIG                        If True, then all components with zero eigenvalues are                        removed, so that the number of components in the                        output may be < n_components (and sometimes even zero                        due to numerical instability). When n_components is                        None, this parameter is ignored and components with                        zero eigenvalues are removed regardless."}, "coef0": {"description": "COEF0         Independent term in poly and sigmoid kernels. Ignored                        by other kernels."}, "alpha": {"description": "ALPHA         Hyperparameter of the ridge regression that learns the                        inverse transform (when fit_inverse_transform=True)."}, "feature_file": {"description": "FEATURE_FILE                        file containing feature data"}, "plot": {"description": "{no,save,show}                        plot options: no, save, show"}, "n_jobs": {"description": "N_JOBS       The number of parallel jobs to run. If -1, then the                        number of jobs is set to the number of CPU cores."}, "plot_title": {"description": "PLOT_TITLE                        Title for the plot  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}}, "path": "./"}, "sk_spectral_embedding": {"arguments": {"zero_based": {"description": "ZERO_BASED"}, "help": {"description": "show this help message and exit"}, "n_components": {"description": "N_COMPONENTS                        The dimension of the projected subspace."}, "n_neighbors": {"description": "N_NEIGHBORS                        default Number of nearest neighbors for                        nearest_neighbors graph building."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "eigen_solver": {"description": "{arpack,lobpcg,amg}                        The eigenvalue decomposition strategy to use. AMG                        requires pyamg to be installed. It can be faster on                        very large, sparse problems, but may also lead to                        instabilities."}, "gamma": {"description": "GAMMA         Kernel coefficient for rbf and poly kernels. Ignored                        by other kernels."}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "random_state": {"description": "RANDOM_STATE                        A pseudo random number generator used for the                        initialization of the residuals when eigen_solver ==                        arpack."}, "affinity": {"description": "{nearest_neighbors,rbf,precomputed}                        nearest_neighbors : construct affinity matrix by knn                        graph, rbf : construct affinity matrix by rbf kernel,                        precomputed : interpret X as precomputed affinity                        matrix, callable : use passed in function as affinity                        the function takes in data matrix (n_samples,                        n_features) and return affinity matrix (n_samples,                        n_samples)."}, "query_id": {"description": "QUERY_ID"}, "comment": {"description": "COMMENT"}, "multilabel": {"description": "MULTILABEL\""}, "n_jobs": {"description": "N_JOBS       The number of jobs to use for the computation. This                        works by computing each of the n_init runs in                        parallel. If -1 all CPUs are used. If 1 is given, no                        parallel computing code is used at all, which is                        useful for debugging. For n_jobs below -1, (n_cpus + 1                        + n_jobs) are used. Thus for n_jobs = -2, all CPUs but                        one are used."}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}}, "path": "./"}, "sk_model": {"arguments": {"zero_based": {"description": "ZERO_BASED"}, "help": {"description": "show this help message and exit"}, "pca": {"description": "PCA"}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "plot": {"description": "{no,save,show}                        plot options: no, save, show"}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "query_id": {"description": "QUERY_ID"}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}, "feature_file": {"description": "FEATURE_FILE                        file containing feature data"}, "comment": {"description": "COMMENT"}, "multilabel": {"description": "MULTILABEL\""}, "plot_title": {"description": "PLOT_TITLE                        Title for the plot"}}, "path": "./"}, "emailit": {"arguments": {"from_address": {"description": "FROM_ADDRESS                        From email address"}, "to": {"description": "TO               To email address"}, "argf": {"description": "ARGF           Read command line arguments from a file.\""}, "help": {"description": "show this help message and exit"}, "subject": {"description": "SUBJECT     Email subject line"}, "text": {"description": "TEXT           Text of the email message"}, "file_attachment": {"description": "FILE_ATTACHMENT                        Files to attach  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}}, "path": "./"}, "sk_svc": {"arguments": {"kernel": {"description": "KERNEL       Specifies the kernel type to be used in the algorithm.                        It must be one of \\xe2\\x80\\x98linear\\xe2\\x80\\x99, \\xe2\\x80\\x98poly\\xe2\\x80\\x99, \\xe2\\x80\\x98rbf\\xe2\\x80\\x99, \\xe2\\x80\\x98sigmoid\\xe2\\x80\\x99,                        \\xe2\\x80\\x98precomputed\\xe2\\x80\\x99 or a callable. If none is given, \\xe2\\x80\\x98rbf\\xe2\\x80\\x99                        will be used. If a callable is given it is used to                        pre-compute the kernel matrix from data matrices; that                        matrix should be an array of shape (n_samples,                        n_samples)."}, "help": {"description": "show this help message and exit"}, "cache_size": {"description": "CACHE_SIZE                        Specify the size of the kernel cache (in MB)."}, "degree": {"description": "DEGREE       Degree of the polynomial kernel function (\\xe2\\x80\\x98poly\\xe2\\x80\\x99).                        Ignored by all other kernels."}, "decision_function_shape": {"description": "{ovo,ovr}                        Whether to return a one-vs-rest (\\xe2\\x80\\x98ovr\\xe2\\x80\\x99) decision                        function of shape (n_samples, n_classes) as all other                        classifiers, or the original one-vs-one (\\xe2\\x80\\x98ovo\\xe2\\x80\\x99)                        decision function of libsvm which has shape                        (n_samples, n_classes * (n_classes - 1) / 2). The                        default of None will currently behave as \\xe2\\x80\\x98ovo\\xe2\\x80\\x99 for                        backward compatibility and raise a deprecation                        warning, but will change \\xe2\\x80\\x98ovr\\xe2\\x80\\x99 in 0.19. New in version                        0.17: decision_function_shape=\\xe2\\x80\\x99ovr\\xe2\\x80\\x99 is recommended.                        Changed in version 0.17: Deprecated                        decision_function_shape=\\xe2\\x80\\x99ovo\\xe2\\x80\\x99 and None."}, "max_iter": {"description": "MAX_ITER   Hard limit on iterations within solver, or -1 for no                        limit."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "gamma": {"description": "GAMMA         Kernel coefficient for \\xe2\\x80\\x98rbf\\xe2\\x80\\x99, \\xe2\\x80\\x98poly\\xe2\\x80\\x99 and \\xe2\\x80\\x98sigmoid\\xe2\\x80\\x99. If                        gamma is \\xe2\\x80\\x98auto\\xe2\\x80\\x99 then 1/n_features will be used                        instead."}, "tol": {"description": "TOL             Tolerance for stopping criterion."}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "C": {"description": "C                 Penalty parameter C of the error term."}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "shrinking": {"description": "SHRINKING                        Whether to use the shrinking heuristic."}, "probability": {"description": "PROBABILITY                        Whether to enable probability estimates. This must be                        enabled prior to calling fit, and will slow down that                        method."}, "coef0": {"description": "COEF0         Independent term in kernel function. It is only                        significant in \\xe2\\x80\\x98poly\\xe2\\x80\\x99 and \\xe2\\x80\\x98sigmoid\\xe2\\x80\\x99."}, "random_state": {"description": "RANDOM_STATE                        The seed of the pseudo random number generator to use                        when shuffling the data for probability estimation.\""}, "verbose": {"description": "VERBOSE     Enable verbose output. Note that this setting takes                        advantage of a per-process runtime setting in libsvm                        that, if enabled, may not work properly in a                        multithreaded context."}, "class_weight": {"description": "CLASS_WEIGHT                        Set the parameter C of class i to class_weight[i]*C                        for SVC. If not given, all classes are supposed to                        have weight one. The \\xe2\\x80\\x9cbalanced\\xe2\\x80\\x9d mode uses the values                        of y to automatically adjust weights inversely                        proportional to class frequencies in the input data as                        n_samples / (n_classes * np.bincount(y))"}}, "path": "./"}, "sk_make_classification": {"arguments": {"n_classes": {"description": "N_CLASSES                        The number of classes (or labels) of the                        classification problem."}, "n_samples": {"description": "N_SAMPLES"}, "zero_based": {"description": "ZERO_BASED"}, "help": {"description": "show this help message and exit"}, "n_clusters_per_class": {"description": "N_CLUSTERS_PER_CLASS                        The number of clusters per class."}, "multilabel": {"description": "MULTILABEL  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "n_features": {"description": "N_FEATURES                        The total number of features. These comprise                        n_informative informative features, n_redundant                        redundant features, n_repeated duplicated features and                        n_features-n_informative-n_redundant- n_repeated                        useless features drawn at random."}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}, "shuffle": {"description": "SHUFFLE     Shuffle the samples and the features."}, "n_informative": {"description": "N_INFORMATIVE                        The number of informative features. Each class is                        composed of a number of gaussian clusters each located                        around the vertices of a hypercube in a subspace of                        dimension n_informative. For each cluster, informative                        features are drawn independently from N(0, 1) and then                        randomly linearly combined within each cluster in                        order to add covariance. The clusters are then placed                        on the vertices of the hypercube."}, "weights": {"description": "WEIGHTS     The proportions of samples assigned to each class. If                        None, then classes are balanced. Note that if                        len(weights) == n_classes - 1, then the last class                        weight is automatically inferred. More than n_samples                        samples may be returned if the sum of weights exceeds                        1."}, "hypercube": {"description": "HYPERCUBE                        If True, the clusters are put on the vertices of a                        hypercube. If False, the clusters are put on the                        vertices of a random polytope."}, "class_sep": {"description": "CLASS_SEP                        The factor multiplying the hypercube dimension."}, "n_redundant": {"description": "N_REDUNDANT                        The number of redundant features. These features are                        generated as random linear combinations of the                        informative features."}, "argf": {"description": "ARGF           Read command line arguments from a file.\""}, "random_state": {"description": "RANDOM_STATE                        RandomState instance or None, optional (default=None)                        If int, random_state is the seed used by the random                        number generator; If RandomState instance,                        random_state is the random number generator; If None,                        the random number generator is the RandomState                        instance used by np.random."}, "scale": {"description": "SCALE         shape [n_features] or None, optional (default=1.0)                        Multiply features by the specified value. If None,                        then features are scaled by a random value drawn in                        [1, 100]. Note that scaling happens after shifting."}, "n_repeated": {"description": "N_REPEATED                        The number of duplicated features, drawn randomly from                        the informative and the redundant features."}, "query_id": {"description": "QUERY_ID"}, "comment": {"description": "COMMENT"}, "shift": {"description": "SHIFT         Shift features by the specified value. If None, then                        features are shifted by a random value drawn in                        [-class_sep, class_sep]."}, "flip_y": {"description": "FLIP_Y       The fraction of samples whose class are randomly                        exchanged."}}, "path": "./"}, "splitit": {"arguments": {"additional_suffix": {"description": "ADDITIONAL_SUFFIX  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "input_file": {"description": "INPUT_FILE"}, "argf": {"description": "ARGF           Read command line arguments from a file.\""}, "prefix": {"description": "PREFIX"}, "help": {"description": "show this help message and exit"}}, "path": "./"}, "sk_isomap": {"arguments": {"zero_based": {"description": "ZERO_BASED"}, "help": {"description": "show this help message and exit"}, "max_iter": {"description": "MAX_ITER   Maximum number of iterations for the arpack solver.                        not used if eigen_solver == dense."}, "path_method": {"description": "{auto,FW,D}                        Method to use in finding shortest path. auto : attempt                        to choose the best algorithm automatically. FW :                        Floyd-Warshall algorithm. D : Dijkstra\\xe2\\x80\\x99s algorithm."}, "n_neighbors": {"description": "N_NEIGHBORS                        number of neighbors to consider for each point."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "eigen_solver": {"description": "{auto,arpack,dense}                        auto: Attempt to choose the most efficient solver for                        the given problem. arpack : Use Arnoldi decomposition                        to find the eigenvalues and eigenvectors. dense : Use                        a direct solver (i.e. LAPACK) for the eigenvalue                        decomposition."}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "n_components": {"description": "N_COMPONENTS                        number of coordinates for the manifold"}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "query_id": {"description": "QUERY_ID"}, "tol": {"description": "TOL             Convergence tolerance passed to arpack or lobpcg. not                        used if eigen_solver == dense."}, "neighbors_algorithm": {"description": "{auto,brute,kd_tree,ball_tree}                        Algorithm to use for nearest neighbors search, passed                        to neighbors.NearestNeighbors instance."}, "comment": {"description": "COMMENT"}, "multilabel": {"description": "MULTILABEL\""}, "n_jobs": {"description": "N_JOBS       The number of parallel jobs to run. If -1, then the                        number of jobs is set to the number of CPU cores."}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}}, "path": "./"}, "sk_svm": {"arguments": {"kernel": {"description": "KERNEL       Specifies the kernel type to be used in the algorithm.                        It must be one of \\xe2\\x80\\x98linear\\xe2\\x80\\x99, \\xe2\\x80\\x98poly\\xe2\\x80\\x99, \\xe2\\x80\\x98rbf\\xe2\\x80\\x99, \\xe2\\x80\\x98sigmoid\\xe2\\x80\\x99,                        \\xe2\\x80\\x98precomputed\\xe2\\x80\\x99 or a callable. If none is given, \\xe2\\x80\\x98rbf\\xe2\\x80\\x99                        will be used. If a callable is given it is used to                        pre-compute the kernel matrix from data matrices; that                        matrix should be an array of shape (n_samples,                        n_samples)."}, "help": {"description": "show this help message and exit"}, "cache_size": {"description": "CACHE_SIZE                        Specify the size of the kernel cache (in MB)."}, "decision_function_shape": {"description": "{ovo,ovr}                        Whether to return a one-vs-rest (\\xe2\\x80\\x98ovr\\xe2\\x80\\x99) decision                        function of shape (n_samples, n_classes) as all other                        classifiers, or the original one-vs-one (\\xe2\\x80\\x98ovo\\xe2\\x80\\x99)                        decision function of libsvm which has shape                        (n_samples, n_classes * (n_classes - 1) / 2). The                        default of None will currently behave as \\xe2\\x80\\x98ovo\\xe2\\x80\\x99 for                        backward compatibility and raise a deprecation                        warning, but will change \\xe2\\x80\\x98ovr\\xe2\\x80\\x99 in 0.19. New in version                        0.17: decision_function_shape=\\xe2\\x80\\x99ovr\\xe2\\x80\\x99 is recommended.                        Changed in version 0.17: Deprecated                        decision_function_shape=\\xe2\\x80\\x99ovo\\xe2\\x80\\x99 and None."}, "degree": {"description": "DEGREE       Degree of the polynomial kernel function (\\xe2\\x80\\x98poly\\xe2\\x80\\x99).                        Ignored by all other kernels."}, "tol": {"description": "TOL             Tolerance for stopping criterion."}, "class_weight": {"description": "CLASS_WEIGHT                        Set the parameter C of class i to class_weight[i]*C                        for SVC. If not given, all classes are supposed to                        have weight one. The \\xe2\\x80\\x9cbalanced\\xe2\\x80\\x9d mode uses the values                        of y to automatically adjust weights inversely                        proportional to class frequencies in the input data as                        n_samples / (n_classes * np.bincount(y))"}, "max_iter": {"description": "MAX_ITER   Hard limit on iterations within solver, or -1 for no                        limit."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "gamma": {"description": "GAMMA         Kernel coefficient for \\xe2\\x80\\x98rbf\\xe2\\x80\\x99, \\xe2\\x80\\x98poly\\xe2\\x80\\x99 and \\xe2\\x80\\x98sigmoid\\xe2\\x80\\x99. If                        gamma is \\xe2\\x80\\x98auto\\xe2\\x80\\x99 then 1/n_features will be used                        instead."}, "plot": {"description": "{no,save,show}                        plot options: no, save, show"}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}"}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "C": {"description": "C                 Penalty parameter C of the error term."}, "shrinking": {"description": "SHRINKING                        Whether to use the shrinking heuristic."}, "probability": {"description": "PROBABILITY                        Whether to enable probability estimates. This must be                        enabled prior to calling fit, and will slow down that                        method."}, "coef0": {"description": "COEF0         Independent term in kernel function. It is only                        significant in \\xe2\\x80\\x98poly\\xe2\\x80\\x99 and \\xe2\\x80\\x98sigmoid\\xe2\\x80\\x99."}, "random_state": {"description": "RANDOM_STATE                        The seed of the pseudo random number generator to use                        when shuffling the data for probability estimation.\""}, "feature_file": {"description": "FEATURE_FILE                        file containing feature data"}, "verbose": {"description": "VERBOSE     Enable verbose output. Note that this setting takes                        advantage of a per-process runtime setting in libsvm                        that, if enabled, may not work properly in a                        multithreaded context."}, "plot_title": {"description": "PLOT_TITLE                        Title for the plot"}}, "path": "./"}, "sk_mean_shift1": {"arguments": {"components": {"description": "COMPONENTS                        number of components to use in PCA analysis"}, "zero_based": {"description": "ZERO_BASED"}, "comment": {"description": "COMMENT"}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}, "argf": {"description": "ARGF           Read command line arguments from a file.\""}, "query_id": {"description": "QUERY_ID"}, "multilabel": {"description": "MULTILABEL  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "feature_file": {"description": "FEATURE_FILE                        file containing feature data"}, "help": {"description": "show this help message and exit"}, "mode": {"description": "MODE           baseline or update"}}, "path": "./"}, "sk_minibatch_kmeans": {"arguments": {"model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "n_clusters": {"description": "N_CLUSTERS                        The number of clusters to form as well as the number                        of centroids to generate."}, "compute_labels": {"description": "COMPUTE_LABELS                        Compute label assignment and inertia for the complete                        dataset once the minibatch optimization has converged                        in fit."}, "precompute_distances": {"description": "{auto,True,False}                        Precompute distances (faster but takes more memory).                        \\xe2\\x80\\x98auto\\xe2\\x80\\x99 : do not precompute distances if n_samples *                        n_clusters > 12 million. This corresponds to about                        100MB overhead per job using double precision. True :                        always precompute distances False : never precompute                        distances"}, "help": {"description": "show this help message and exit"}, "max_iter": {"description": "MAX_ITER   Maximum number of iterations of the k-means algorithm                        for a single run."}, "batch_size": {"description": "BATCH_SIZE                        Size of the mini batches."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "init_size": {"description": "INIT_SIZE                        Number of samples to randomly sample for speeding up                        the initialization (sometimes at the expense of                        accuracy): the only algorithm is initialized by                        running a batch KMeans on a random subset of the data.                        This needs to be larger than n_clusters.  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "reassignment_ratio": {"description": "REASSIGNMENT_RATIO                        Control the fraction of the maximum number of counts                        for a center to be reassigned. A higher value means                        that low count centers are more easily reassigned,                        which means that the model will take longer to                        converge, but should converge in a better clustering."}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "tol": {"description": "TOL             Relative tolerance with regards to inertia to declare                        convergence"}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}\""}, "algorithm": {"description": "{auto,full,elkan}                        K-means algorithm to use. The classical EM-style                        algorithm is \\xe2\\x80\\x9cfull\\xe2\\x80\\x9d. The \\xe2\\x80\\x9celkan\\xe2\\x80\\x9d variation is more                        efficient by using the triangle inequality, but                        currently doesn\\xe2\\x80\\x99t support sparse data. \\xe2\\x80\\x9cauto\\xe2\\x80\\x9d chooses                        \\xe2\\x80\\x9celkan\\xe2\\x80\\x9d for dense data and \\xe2\\x80\\x9cfull\\xe2\\x80\\x9d for sparse data."}, "max_no_improvement": {"description": "MAX_NO_IMPROVEMENT                        Control early stopping based on the consecutive number                        of mini batches that does not yield an improvement on                        the smoothed inertia. To disable convergence detection                        based on inertia, set max_no_improvement to None."}, "random_state": {"description": "RANDOM_STATE                        The generator used to initialize the centers. If an                        integer is given, it fixes the seed. Defaults to the                        global numpy random number generator."}, "verbose": {"description": "VERBOSE     Verbosity mode."}, "init": {"description": "{k-means++,random,ndarray}                        Method for initialization, defaults to k-means++:                        k-means++ : selects initial cluster centers for k-mean                        clustering in a smart way to speed up convergence. See                        section Notes in k_init for more details. random:                        choose k observations (rows) at random from data for                        the initial centroids. If an ndarray is passed, it                        should be of shape (n_clusters, n_features) and gives                        the initial centers."}, "copy_x": {"description": "COPY_X       When pre-computing distances it is more numerically                        accurate to center the data first. If copy_x is True,                        then the original data is not modified. If False, the                        original data is modified, and put back before the                        function returns, but small numerical differences may                        be introduced by subtracting and then adding the data                        mean."}, "n_init": {"description": "N_INIT       Number of time the k-means algorithm will be run with                        different centroid seeds. The final results will be                        the best output of n_init consecutive runs in terms of                        inertia."}, "n_jobs": {"description": "N_JOBS       The number of jobs to use for the computation. This                        works by computing each of the n_init runs in                        parallel. If -1 all CPUs are used. If 1 is given, no                        parallel computing code is used at all, which is                        useful for debugging. For n_jobs below -1, (n_cpus + 1                        + n_jobs) are used. Thus for n_jobs = -2, all CPUs but                        one are used."}}, "path": "./"}, "sk_make_blobs": {"arguments": {"center_box": {"description": "CENTER_BOX                        : pair of floats (min, max), optional (default=(-10.0,                        10.0)) The bounding box for each cluster center when                        centers are generated at random."}, "centers": {"description": "CENTERS     or array of shape [n_centers, n_features], optional                        (default=3) The number of centers to generate, or the                        fixed center locations."}, "cluster_std": {"description": "CLUSTER_STD                        or sequence of floats, optional (default=1.0) The                        standard deviation of the clusters."}, "multilabel": {"description": "MULTILABEL  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "argf": {"description": "ARGF           Read command line arguments from a file.\""}, "help": {"description": "show this help message and exit"}, "n_features": {"description": "N_FEATURES                        The total number of features. These comprise                        n_informative informative features, n_redundant                        redundant features, n_repeated duplicated features and                        n_features-n_informative-n_redundant- n_repeated                        useless features drawn at random."}, "zero_based": {"description": "ZERO_BASED"}, "query_id": {"description": "QUERY_ID"}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}, "random_state": {"description": "RANDOM_STATE                        RandomState instance or None, optional (default=None)                        If int, random_state is the seed used by the random                        number generator; If RandomState instance,                        random_state is the random number generator; If None,                        the random number generator is the RandomState                        instance used by np.random."}, "comment": {"description": "COMMENT"}, "shuffle": {"description": "SHUFFLE     Shuffle the samples and the features."}, "n_samples": {"description": "N_SAMPLES"}}, "path": "./"}, "sk_plot": {"arguments": {"plot_file": {"description": "PLOT_FILE                        Plot output file"}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "help": {"description": "show this help message and exit  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "projection": {"description": "{3d,polar}"}, "feature_file2": {"description": "FEATURE_FILE2\""}, "type": {"description": "TYPE"}, "feature_file": {"description": "FEATURE_FILE                        file containing feature data"}, "model_file": {"description": "MODEL_FILE                        load existing model from file., default is                        DummyClassifier"}, "plot": {"description": "{no,save,show}                        plot options: no, save, show"}, "plot_title": {"description": "PLOT_TITLE                        Title for the plot"}}, "path": "./"}, "sk_pca": {"arguments": {"whiten": {"description": "WHITEN"}, "zero_based": {"description": "ZERO_BASED"}, "copy": {"description": "COPY           If False, data passed to fit are overwritten and                        running fit(X), transform(X) will not yield the                        expected results, use fit_transform(X) instead."}, "help": {"description": "show this help message and exit"}, "multilabel": {"description": "MULTILABEL\""}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "tol": {"description": "TOL             Convergence tolerance for arpack. If 0, optimal value                        will be chosen by arpack."}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "n_components": {"description": "N_COMPONENTS                        number of components to use in PCA analysis"}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "random_state": {"description": "RANDOM_STATE                        A pseudo random number generator used for the                        initialization of the residuals when eigen_solver ==                        \\xe2\\x80\\x98arpack\\xe2\\x80\\x99."}, "output_file": {"description": "OUTPUT_FILE                        file containing output"}, "query_id": {"description": "QUERY_ID"}, "comment": {"description": "COMMENT"}, "svd_solver": {"description": "{auto,full,arpack,randomized}"}, "iterated_power": {"description": "ITERATED_POWER"}}, "path": "./"}, "sk_naive_bayes": {"arguments": {"kernel": {"description": "KERNEL       Specifies the kernel type to be used in the algorithm.                        It must be one of \\xe2\\x80\\x98linear\\xe2\\x80\\x99, \\xe2\\x80\\x98poly\\xe2\\x80\\x99, \\xe2\\x80\\x98rbf\\xe2\\x80\\x99, \\xe2\\x80\\x98sigmoid\\xe2\\x80\\x99,                        \\xe2\\x80\\x98precomputed\\xe2\\x80\\x99 or a callable. If none is given, \\xe2\\x80\\x98rbf\\xe2\\x80\\x99                        will be used. If a callable is given it is used to                        pre-compute the kernel matrix from data matrices; that                        matrix should be an array of shape (n_samples,                        n_samples)."}, "help": {"description": "show this help message and exit"}, "cache_size": {"description": "CACHE_SIZE                        Specify the size of the kernel cache (in MB)."}, "degree": {"description": "DEGREE       Degree of the polynomial kernel function (\\xe2\\x80\\x98poly\\xe2\\x80\\x99).                        Ignored by all other kernels."}, "decision_function_shape": {"description": "{ovo,ovr}                        Whether to return a one-vs-rest (\\xe2\\x80\\x98ovr\\xe2\\x80\\x99) decision                        function of shape (n_samples, n_classes) as all other                        classifiers, or the original one-vs-one (\\xe2\\x80\\x98ovo\\xe2\\x80\\x99)                        decision function of libsvm which has shape                        (n_samples, n_classes * (n_classes - 1) / 2). The                        default of None will currently behave as \\xe2\\x80\\x98ovo\\xe2\\x80\\x99 for                        backward compatibility and raise a deprecation                        warning, but will change \\xe2\\x80\\x98ovr\\xe2\\x80\\x99 in 0.19. New in version                        0.17: decision_function_shape=\\xe2\\x80\\x99ovr\\xe2\\x80\\x99 is recommended.                        Changed in version 0.17: Deprecated                        decision_function_shape=\\xe2\\x80\\x99ovo\\xe2\\x80\\x99 and None."}, "max_iter": {"description": "MAX_ITER   Hard limit on iterations within solver, or -1 for no                        limit."}, "model_file": {"description": "MODEL_FILE                        load existing model from file."}, "gamma": {"description": "GAMMA         Kernel coefficient for \\xe2\\x80\\x98rbf\\xe2\\x80\\x99, \\xe2\\x80\\x98poly\\xe2\\x80\\x99 and \\xe2\\x80\\x98sigmoid\\xe2\\x80\\x99. If                        gamma is \\xe2\\x80\\x98auto\\xe2\\x80\\x99 then 1/n_features will be used                        instead."}, "tol": {"description": "TOL             Tolerance for stopping criterion."}, "action": {"description": "{fit,fit_predict,fit_transform,predict,transform,score}  -t                    Copy upstream data to downstream.  -s                    Supress dict output.  -b                    Disable read arguments from stdin."}, "model_output_file": {"description": "MODEL_OUTPUT_FILE                        load existing model from file."}, "C": {"description": "C                 Penalty parameter C of the error term."}, "argf": {"description": "ARGF           Read command line arguments from a file."}, "shrinking": {"description": "SHRINKING                        Whether to use the shrinking heuristic."}, "probability": {"description": "PROBABILITY                        Whether to enable probability estimates. This must be                        enabled prior to calling fit, and will slow down that                        method."}, "coef0": {"description": "COEF0         Independent term in kernel function. It is only                        significant in \\xe2\\x80\\x98poly\\xe2\\x80\\x99 and \\xe2\\x80\\x98sigmoid\\xe2\\x80\\x99."}, "random_state": {"description": "RANDOM_STATE                        The seed of the pseudo random number generator to use                        when shuffling the data for probability estimation.\""}, "verbose": {"description": "VERBOSE     Enable verbose output. Note that this setting takes                        advantage of a per-process runtime setting in libsvm                        that, if enabled, may not work properly in a                        multithreaded context."}, "class_weight": {"description": "CLASS_WEIGHT                        Set the parameter C of class i to class_weight[i]*C                        for SVC. If not given, all classes are supposed to                        have weight one. The \\xe2\\x80\\x9cbalanced\\xe2\\x80\\x9d mode uses the values                        of y to automatically adjust weights inversely                        proportional to class frequencies in the input data as                        n_samples / (n_classes * np.bincount(y))"}}, "path": "./"}, "ff_parse": {"arguments": {"ff_dag_id": {"description": "FF_DAG_ID"}, "trigger_dir": {"description": "TRIGGER_DIR                        trigger the dag if a file is created in this directory"}, "ff_schedule_interval": {"description": "FF_SCHEDULE_INTERVAL"}, "ff_dag_dir": {"description": "FF_DAG_DIR"}, "pattern": {"description": "PATTERN     trigger the dag if the file matches this pattern'"}, "pipeline": {"description": "PIPELINE   shell command pipleline"}, "help": {"description": "show this help message and exit"}}, "path": "./"}}